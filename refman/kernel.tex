%\part{Reference Manual}
\chapter{Lisa's Trusted Kernel}
\label{chapt:kernel}
Lisa's kernel is the starting point of Lisa, formalising the foundations of the whole theorem prover. It is the only trusted code base, meaning that if it is bug-free then no further erroneous code can violate the soundness property and prove invalid statements. Hence, the two main goals of the kernel are to be efficient and trustworthy.


Lisa's foundations are based on traditional (in the mathematical community) foundational theory of all mathematics, but with some extensions and modifications to more closely match common mathematical practice:
\begin{itemize}
  \item The syntax of Lisa's statement is an extension of first-order logic with lambda terms named \textbf{\lambdafol} (see \autoref{sec:FOL}).
  \item The deductive system of Lisa's kernel is \textbf{Sequent Calculus}.
  \item The axiomatic theory is \textbf{ZFC Set Theory}, but the kernel is actually theory-agnostic and is sound to use with any other set of axioms. Set theory (see \autoref{chapt:settheory}).
\end{itemize}

\section{\lambdafol: First Order Logic with Lambda Terms}
\label{sec:FOL}

First-order logic has many useful properties, but the way it is usually defined is not very convenient for practical use. In particular, it does not allow to write self-contained terms binding a variable. A typical example of this is integrals:
$$
\int_0^1 x^2 dx
$$
$x$ is a subterm of this expression, but it is bound by the integral sign $\int ... dx$. Another example is notation for set comprehensions:
$$
\lbrace x \in \mathbb N \mid \exists y. x = y^2 \rbrace
$$
here, $x$ is again a bound variable, and moreover the expression contains a subformula. Both the integral and the comprehensions are supposed to be terms: they denote elements of the universe, unlike formulas. But in pure first-order logic, terms cannot bind variables nor contain formulas. To adress this, Lisa uses an extension of first-order logic with lambda terms, called \lambdafol.

\subsection{Expressions}

The basic elements of Lisa are called \textit{Expressions}, generalising terms and formulas. Expressions are terms of the simply typed lambda-calculus, with two basic types: \textit{Prop}, or propositions, corresponding to formulas, and \textit{Ind}, or individuals, corresponding to terms. To disambiguate from Scala types and set-theoretic types, we call Prop and Sort \textit{Sorts}. Formally:

\begin{definition}[Identifiers]
  Identifiers are pairs of strings and positive integers used to name symbols. The integer partis convenient to quickly compute fresh identifiers and.
  \begin{align}
    \textit{ID} := & ~\text{ID(\textit{String}, \textit{Int})} \\
  \end{align}
  Identifiers cannot contain the symbols \lstinline|()[]{}?,;_| nor whitespace. The canonical representation of an identifier is
  
$$
\text{ID}(\text{"foo"}, i) = \begin{cases}
    \text{foo} & \text{ if } i=0\\
    \text{foo\textunderscore}i & \text{ else}
  \end{cases}
$$

\end{definition}

\begin{definition}[Sorts]
  Sorts are defined by the following grammar:
  \begin{align}
    \mathcal{S} := & ~\text{Prop} \mid \text{Ind} \mid \mathcal{S} \rightarrow \mathcal{S} \\
  \end{align}
  
  $A \rightarrow B$ is the sort of expressions taking arguments of sort $A$ and returning a result of sort $B$. Note that $\rightarrow$ associates to the right, i.e. $A \rightarrow B \rightarrow C$ is the same as $A \rightarrow (B \rightarrow C)$.
\end{definition}

\begin{definition}[Expressions]
  We define sets of \textit{variables} $\mathcal{V}$ and \textit{constants} $\mathcal{C}$:
  \begin{align}
    \mathcal{V} := & ~\text{Var}(\textit{ID}, \mathcal{S}) \\
    \mathcal{C} := & ~\text{Cst}(\textit{ID}, \mathcal{S}) \\
  \end{align}
  When unambiguous, we typically represent variables and constants using the representation of its identifier, optionally with the sort following a colon, as in $x: \Ind$.

  An expression is either a variable, a constant, an application of an expression to another expression, or an abstraction of a variable over an expression. Expressions are always uniquely \textit{sorted}. Formally:
  \begin{align}
    \mathcal{E} := & ~\mathcal{V}: \mathcal{S} \\
    & \mid \mathcal{C}: \mathcal{S} \\
    & \mid \text{App}(\mathcal{E}: \mathcal{S}_1 \rightarrow \mathcal{S}_2, \mathcal{E}: \mathcal{S}_1): \mathcal{S}_2 \\
    & \mid \text{Abs}(\mathcal{V}: \mathcal{S}_1, \mathcal{E}: \mathcal{S}_2): \mathcal{S}:1 \rightarrow \mathcal{S}_2 \\
  \end{align}
  We usually represent App$(f, x)$ as $f(x)$ and Abs$(x, e)$ as $\lambda x. e$. In $\lambda x. e$, All the occurences of $x$ in $e$ are called bound.
  Every expression must belong to a sort. Ill-sorted expressions are not forbidden.

  Expressions of sort \Prop are called \textit{formulas}. Expressions of sort \Ind are called \textit{terms}.
  Expressions of sort $\Ind \rightarrow \Ind \rightarrow ... \rightarrow \Ind$ are called \textit{functionals}.
  Expressions of sort $\Prop \rightarrow \Prop \rightarrow ... \rightarrow \Prop$ are called \textit{predicates}.

\end{definition}

\begin{definition}[Constants]
  We predefine some important logical constants:
  \begin{align*}
    = \quad: & \Ind \rightarrow \Ind \rightarrow \Prop \\
    \top \quad: & \Prop \\
    \bot \quad: & \Prop \\
    \neg \quad: & \Prop \rightarrow \Prop \\
    \land \quad: & \Prop \rightarrow \Prop \rightarrow \Prop \\
    \lor \quad: & \Prop \rightarrow \Prop \rightarrow \Prop \\
    \Rightarrow \quad: & \Prop \rightarrow \Prop \rightarrow \Prop \\
    \Leftrightarrow \quad: & \Prop \rightarrow \Prop \rightarrow \Prop \\
    \forall \quad: & (\Ind \rightarrow \Prop) \rightarrow \Prop \\
    \exists \quad: & (\Ind \rightarrow \Prop) \rightarrow \Prop \\
    \epsilon \quad: & (\Ind \rightarrow \Prop) \rightarrow \Ind 
  \end{align*}

  They have special meaning for the deduction system of lisa, but syntactically behave the same as user-defined constants.

  We call $\forall$, $\exists$ and $\epsilon$ \textit{binders}. We often write bound expressions such as $\forall(\lambda x. P(x) \land Q(x))$ as $\forall x. P(x) \land Q(x)$, like in traditional first-order logic.
\end{definition}

\begin{example}
  The following are examples of expressions:
  \begin{tabularx}{\textwidth}{|l | X|}\hline
    $\Ind$ & The sort of individuals, i.e. elements of the universe such as sets, numbers, etc. \\\hline
    $\emptyset: \Ind$ & The empty set \\\hline
    $7: \Ind$ & The number 7 \\\hline
    $\Prop$ & The sort of formulas, which can be either true or false. \\\hline
    $\top: \Prop$ & The constant true \\\hline
    $\bot: \Prop$ & The constant false \\\hline
    $\Ind \rightarrow \Ind$ & The sort of functionals, taking one individuals as argument and returning an individual. \\\hline
    $\mathcal P: \Ind \rightarrow \Ind$  & The powerset operator \\\hline
    $\mathcal P(\emptyset): \Ind$ & The powerset of the empty set \\\hline
    $(21 + 6) / 3: \Ind$ & The result of the division of an arithmetic expression \\\hline
    $\Ind \rightarrow \Ind \rightarrow \Prop$ & The sort of predicates of arity 2. \\\hline
    $\in: \Ind \rightarrow \Ind \rightarrow \Prop$ & The membership predicate \\\hline
    $3 \in \mathbb N : \Prop$ & The formula stating that 3 is a natural number \\\hline
    $\Prop \rightarrow \Prop \rightarrow \Prop$ & The sort of connectors of arity 2.\\\hline
    $\land: \Prop \rightarrow \Prop \rightarrow \Prop$ & The conjunction connector \\\hline
    $\bot \land 3 \in \mathbb N: \Prop$ & A formula \\\hline

    $\lambda x. x^2+1: \Ind \rightarrow \Ind$ & The functional mapping $x$ to $x^2+1$ \\\hline
    $\lambda x. x = f(x): \Prop$ & The predicate mapping $x$ to whether $x$ is a fixpoint of $f$ \\\hline
  \end{tabularx}
\end{example}

\paragraph{Convention} Throughout this document, and in the code base, we adopt the following conventions:We use $e$, $e_1$, $e_2$ to denote arbitrary expressions.
We use $r$, $s$, $t$, $u$ to denote arbitrary terms, $a$, $b$, $c$ to denote constants of type \Ind, $x$, $y$, $z$ to denote variables of type \Ind and $f$, $g$, $h$ to denote constant or variables of type $\Ind \rightarrow ... \Ind$. 

We use greek letters such as $\phi$, $\psi$, $\tau$ to denote arbitrary formulas and $X$, $Y$, $Z$ to denote variables of type \Prop. We use $P$, $Q$, $R$ to denote constants and variables of type $\Prop \rightarrow ... \rightarrow \Prop$. Sets or sequences of formulas are denoted with capital greek letters $\Pi$, $\Sigma$, $\Gamma$, $\Delta$, etc.

$\equiv$ represents both $=$ and $\iff$, depending on whether the arguments are terms or formulas.

\subsection{Capture-Avoiding Substitution and Beta-Reduction}
An important operation on expressions is the substitution of variables by expressions of the same type. 
\begin{definition}[Capture-avoiding Substitution of variables]
  Given a base expression $e$, a variable $x: A$ and another expression $e_1:A$, the substitution of $x$ by $e_1$ inside $t$ is denoted by $ t[x := e] $ and is computed by replacing all occurences of $x$ by $r$.

  Formally:
  \begin{align*}
    (x)[x := e] \equiv\quad& e & \\
    (y)[x := e] \equiv\quad& y & \text{ if } x \neq y \\
    (f(e_1))[x := e] \equiv\quad& f(e_1[x := e]) & \\
    (\lambda x. e_1)[x := e] \equiv\quad& \lambda x. e_1 & \\
    (\lambda y. e_1)[x := e] \equiv\quad& \lambda y. e_1[x := e] &\text{ if } x \neq y \text{ and } y \notin \text{free}(e) \\
    (\lambda y. e_1)[x := e] \equiv\quad& \lambda z. e_1[y := z][x := e] &\text{ otherwise, with $z$ fresh} \\
  \end{align*}
  This is called \textit{capture-avoiding substitution}, because the last two lines ensure that the free variables of $e$ stay free, independently of the name of bound variables.
\end{definition}

Applications of an abstraction to an argument \textit{beta-reduce}, as usual in lambda calculus. For example, 
$$(\lambda x. x^2+1)(3) \leadsto 3^2+1$$
It is a theorem of the simply typed lambda calculus, called the Church-Rosser theorem, that when we keep applying such reduction, we eventually reach a normal form that cannot be further reduced. This is called the \textit{beta normal form}. Two expressions with the same beta normal form are called \textit{alpha-equivalent} Moreover, if two expressions are identical up to renaming of bound variables, the expressions are  called \textit{alpha-equivalent}. In Lisa, expressions whose beta normal forms are alpha-equivalent are considered logicaly the same. Note however that their representation as datastructure may not be the same, and this can influence the behaviour of programs acting on them.



\subsection{Substitution}
\label{subsec:substitution}
On top of basic building blocks of terms and formulas, there is one important type of operation: substitution of schematic symbols, which has to be implemented in a capture-avoiding way. We start with the subcase of variable substitution:
\begin{definition}[Capture-avoiding Substitution of variables]
  Given a base term $t$, a variable $x$ and another term $r$, the substitution of $x$ by $r$ inside $t$ is denoted by $ t[x := r] $ and is computed by replacing all occurences of $x$ by $r$.

  Given a formula $\phi$, the substitution of $x$ by $r$ inside $\phi$ is defined recursively in the standard way for connectors and predicates
  %
  \begin{gather*}
    (\phi \land \psi)[x := r] \equiv \phi[x := r] \land \psi[x := r]~,\\
    P(t_1, t_2, \ldots, t_n)[x := r] \equiv P(t_1[x := r], t_2[x := r], \ldots, t_n[x := r])~,
  \end{gather*}
  %
  and for binders as
  %
  $$
    (\forall x. \psi)[x := r] \equiv \forall x. \psi
  $$
  $$
    (\forall y. \psi)[x := r] \equiv \forall y. \psi[x := r]
  $$
  if $y \neq x$ and $y$ does not appear in $r$, and
  $$
    (\forall y. \psi)[x := r] \equiv \forall z. \psi[y := z][x := r]~,
  $$
  with any fresh variable $z$ (which is not free in $r$ and $\phi$) otherwise.
\end{definition}


\begin{example}[Combined substitution and beta-reduction] \phantom{ }
  \begin{center}
    \begin{tabular}{|c|r c l|c|}
      \noalign{\vspace{0.5em}}
      \hline
      Base term            & \multicolumn{3}{c|}{Substitution} & Result                                                                 \\
      \hline
      $f(0, 3)$           & $f$                              & $\rightarrow$ & $\lambda x.y. x+y$         & $0+3$                     \\
      $f(0, 3)$           & $f$                              & $\rightarrow$ & $\lambda y.x. x-y$         & $3-0$                     \\
      $f(0, 3)$           & $f$                              & $\rightarrow$ & $\lambda x.y. y+y-10$      & $3+3-10$                  \\
      $10 \times {g(x)}$  & $g$                              & $\rightarrow$ & $\lambda x. x^2$           & $10 \times x^2$           \\
      $10 \times {g(50)}$ & $g$                              & $\rightarrow$ & $\lambda x. `f(x+2, z)$    & $10 \times {f(50+2, z)}$ \\
      $f(x, x+y)$         & $f$                              & $\rightarrow$ & $\lambda x.y. \cos(x-y)*y$ & $\cos(x-(x+y))*(x+y)$     \\
      $f(0, 3) = f(x, x)$            & $f$                              & $\rightarrow$ & $\lambda x.y. x+y$ & $0+3 = x+x$                   \\
      $\forall x. f(0, 3) = f(x, x)$ & $f$                              & $\rightarrow$ & $\lambda x.y. x+y$ & $\forall x. 0+3 = x+x$        \\

      $\exists y. `f(y) \leq `f(5)$    & $f$                              & $\rightarrow$ & $\lambda x. x+y$   & $\exists y_1. y_1+y \leq 5+y$ \\

      \hline
    \end{tabular}
  \end{center}
\end{example}

\subsection{The Equivalence Checker}
\label{subsec:equivalencechecker}

While proving theorems, trivial syntactical transformations such as $p\land q \equiv q\land p$  increase the length of proofs, which is desirable neither to the user nor the machine. Moreover, the proof checker will very often have to check whether two formulas that appear in different sequents are the same. Hence, instead of using pure syntactical equality, Lisa implements an equivalence checker able to detect a class of equivalence-preserving logical transformations. For example, we would like the  formulas $p\land q$ and $q\land p$ to be naturally treated as equivalent.

For soundness, the relation decided by the algorithm should be contained in the $\iff$ ``if and only if'' relation of first order logic. However, it is well known that this relationship is in general undecidable, and even the $\iff$ relation for propositional logic is coNP-complete. For practicality, we need a relation that is efficiently computable.

Orthologic is such a relation: It is a weaker theory than classical logic, because it does not include the distributivity law of $\land$ and $\lor$, but it admits a quadratic-time normalization algorithm for propositional formulas \cite{guilloudFormulaNormalizationsVerification2023}. The structure underlying orthologic (its Lindenbaum algebra) is that of ortholattices, similar to the relationshipbetween classical logic and Boolean algebra. The laws of orthologic are shown in \autoref{tab:ortholatticeLaws}.

\begin{table}[bth]
  \centering
  \begin{tabular}{r c @{\hskip 2em} | @{\hskip 2em} r c}
    L1: & $x \lor y = y \lor x$                    & L1': & $x \land y = y \land x$                      \\
    L2: & $x \lor ( y \lor z) = (x \lor y) \lor z$ & L2': & $x \land ( y \land z) = (x \land y) \land z$ \\
    L3: & $x \lor x = x$                           & L3': & $x \land x = x$                              \\
    L4: & $x \lor 1 = 1$                           & L4': & $x \land 0 = 0$                              \\
    L5: & $x \lor 0 = x$                           & L5': & $x \land 1 = x$                              \\
    L6: & $\neg \neg x = x$                        & L6': & same as L6                                   \\
    L7: & $x \lor \neg x = 1$                      & L7': & $x \land \neg x = 0$                         \\
    L8: & $\neg (x \lor y) = \neg x \land \neg y$  & L8': & $\neg (x \land y) = \neg x \lor \neg y$      \\
    L9: & $x \lor (x \land y) = x$                 & L9': & $x \land (x \lor y) = x$                     \\
  \end{tabular}
  %
  \caption{Laws of ortholattices, an algebraic theory with signature $(S, \land, \lor, 0, 1, \neg)$.}
  \label{tab:ortholatticeLaws}
\end{table}

As a special kind of lattices, ortholattices can be viewed as partially ordered sets, with the ordering relation on two elements $a$ and $b$ of an ortholattice defined as
\(
a\leq b \iff a \land b = a
\), which, by absorption (L9), is also equivalent to $a \lor b = b$. If $s$ and $t$ are propositional formulas, we denote $s \leq_\OL t $ if and only if $s \leq t$, is provable from the axioms of \autoref{tab:ortholatticeLaws}.
We write $s\sim_\OL t$ if both $s\leq_\OL t$ and $s\geq_\OL t$ hold.
\autoref{thm:OL} is the main result we rely on.

\begin{theorem}[\cite{guilloudFormulaNormalizationsVerification2023}]
  \label{thm:OL}
  There exists an algorithm running in worst case quadratic time producing, for any terms $s$ over the signature $(\land, \lor, \neg)$, a normal form $\text{NF}_{\OL}(s)$
  such that for any $t$, $s \sim_\OL t$ if and only if $\text{NF}_{\OL}(s) = \text{NF}_{\OL}(t)$. The algorithm is also capable of deciding if $s \leq_{OL} t$ holds in quadratic time.
\end{theorem}
Moreover, the algorithm works with structure sharing with the same complexity, which is very relevant for example when $x \leftrightarrow y$ is expanded to $(x \land y) \lor (\neg x \land \neg y)$. It can produce a normal form in this case as well.

Lisa's kernel contains a generalization of this algorithm to \lambdafol, which also includes additional reasoning rules. It first beta-normalize expressions, expresses the formula using de Bruijn indices, and desugars $\exists. \phi$ into $\neg \forall. \neg \phi$, $\phi\Leftrightarrow\psi$ into $(\phi\Rightarrow\psi)\land(\psi\Rightarrow\phi)$, and $\phi\Rightarrow\psi$ into $\neg \phi \lor \psi$. It then applies OL normalization,  with the the additional rules of \autoref{tab:Olextension}.

\begin{table}[ht]
  \centering
  \begin{tabular}{c | l | l}
      & To decide...                                                                             & Try...                                           \\
    \hline
    1 & $\lbrace \land, \lor, \rightarrow, \leftrightarrow, \neg \rbrace(\vec{\phi}) \leq \psi $ & Base algorithm                                         \\
    2 & $\phi \leq \lbrace \land, \lor, \rightarrow, \leftrightarrow, \neg \rbrace(\vec{\psi}) $ & Base algorithm                                         \\
    3 & $s_1 = s_2 \leq t_1 = t_2$                                                               & $\lbrace s_1, s_2 \rbrace == \lbrace t_1, t_2 \rbrace$ \\
    4 & $\phi \leq t_1 = t_2$                                                                    & $t_1 == t_2$                                           \\
    %(s_1 \sim_\Ol t_1 \& s_2 \sim_\Ol t_2) || (s_1 \sim_\Ol t_2 \& s_2 \sim_\Ol t_1)
    5 & $\forall. \phi \leq \forall. \psi$                                                       & $\phi \leq \psi$                                       \\
    6 & $C(\phi_1,...,\phi_n) \leq C(\psi_1,...,\psi_n)$                         & $\phi_i \sim_\OL \psi_i$, for every $1 \le i \le n$    \\

    7 & Anything else                                                                            & \lstinline|false|
  \end{tabular}

  \caption{Extension of OL algorithm to first-order logic. We call it the \FOLalg{} algorithm. $=$ denotes the equality predicate in FOL, while $==$ denotes syntactic equality of terms.
    \label{tab:Olextension}}
\end{table}

A more detailed discussion of extension of ortholattices to first-order logic, proof of correctness and implementation details can be found in \cite{guilloudFormulaNormalizationsVerification2023} and \cite{guilloudLISAModernProof2023}.




\section{Proofs in Sequent Calculus for \lambdafol}
\label{sec:proofs_lk}
\subsection{Sequent Calculus}
\label{subsec:lk}
The deductive system used by Lisa is an extended version of the classical Sequent Calculus. 
%
\begin{definition}
  A \textbf{sequent} is a pair $(\Gamma, \Sigma)$ of (possibly empty) sets of formulas, noted:
  %
  \begin{gather*}
    \Gamma \vdash \Sigma~.
  \end{gather*}
  %
  The intended semantic of such a sequent is:
  %
  \begin{equation*}
    \label{eq:SequentSemantic}
    \bigwedge \Gamma \implies \bigvee \Sigma~.
  \end{equation*}

  The sequent may also be written with the elements of the sets enumerated explicitly as
  %
  \begin{equation*}
    \gamma_1, \gamma_2, \ldots, \gamma_n \vdash \sigma_1, \sigma_2, \ldots, \sigma_m~.
  \end{equation*}
\end{definition}
A sequent $\phi \vdash \psi$ is logically (but not conceptually) equivalent to a sequent $\vdash \phi \rightarrow \psi$. The distinction is similar to the distinction between meta-implication and inner implication in Isabelle \cite{paulsonIsabelleNext7001993}, for example. Typically, a theorem or a lemma should have its various assumptions on the left-hand side of the sequent and a single conclusion on the right. During proofs however, there may be multiple elements on the right side. \footnote{In a strict description of Sequent Calculus, this is in particular needed to have double negation elimination.}

Sequents are manipulated in a proof using \emph{deduction rules}. A deduction rule, also called a proof step, has zero or more prerequisite sequents (which we call \emph{premises} of the rule) and one conclusion sequent. All the basic deduction rules used in Lisa's kernel are shown in \autoref{fig:deduct_rules_1} and \autoref{fig:deduct_rules_2}.
This includes first rules of propositional logic, then rules for quantifiers, then equality rules. Moreover, we include equal-for-equal and equivalent-for-equivalent substitutions. While those substitution rules are deduced steps, and hence could technically be omitted, simulating them can sometimes take a high number of steps, so they are included as base steps for efficiency.
Finally, the two rules Restate and Weakening leverage the $\FOLalg$ algorithm.

%For proof checking, the kernel implementation of these proof steps explicitly take all required arguments, such as the formulas central to the manipulation. These are intended for internal use, and most arguments can be inferred and are automatically generated when writing proofs with the DSL (\autoref{subsec:dsl}). While user-developed deduced steps may also use the DSL, in cases where arguments are easily known, kernel steps retain their utility in that they may be directly emitted for efficiency, see \autoref{subsec:tacticDev} for discussion on this. The following is an example proof, that of Pierce's law, in sequent calculus, and its encoding utilizing kernel steps: 
%Start of first set of deduction rules


\begin{figure}
  \scalebox{.88}{
    \begin{minipage}{\textwidth}
      \begin{center}
        \begin{tabular}{l l}
          \AxiomC{}
          \RightLabel{\text { Hypothesis}}
          \UnaryInfC{$\Gamma, \phi \vdash \phi, \Delta$}
          \DisplayProof &
          \AxiomC{$\Gamma \vdash \phi, \Delta$}
          \AxiomC{$\Sigma, \phi \vdash \Pi$}
          \RightLabel{\text{ Cut}}
          \BinaryInfC{$\Gamma, \Sigma \vdash \Delta, \Pi$}
          \DisplayProof
          \\[5ex]

          \AxiomC{$\Gamma, \phi, \psi \vdash \Delta$}
          \RightLabel{\text { LeftAnd}}
          \UnaryInfC{$\Gamma, \phi \land \psi \vdash \Delta$}
          \DisplayProof &
          \AxiomC{$\Gamma \vdash \phi, \Delta$}
          \AxiomC{$\Sigma \vdash \psi, \Pi$}
          \RightLabel{\text{ RightAnd}}
          \BinaryInfC{$\Gamma, \Sigma \vdash \phi \land \psi,  \Delta, \Pi$}
          \DisplayProof
          \\[5ex]

          \AxiomC{$\Gamma, \phi \vdash \Delta$}
          \AxiomC{$\Sigma, \psi \vdash \Pi$}
          \RightLabel{\text{ LeftOr}}
          \BinaryInfC{$\Gamma, \Sigma, \phi\lor \psi \vdash \Delta, \Pi$}
          \DisplayProof &
          \AxiomC{$\Gamma \vdash \phi, \psi \Delta$}
          \RightLabel{\text{ RightOr}}
          \UnaryInfC{$\Gamma \vdash \phi \lor \psi,  \Delta$}
          \DisplayProof
          \\[5ex]

          \AxiomC{$\Gamma \vdash \phi, \Delta$}
          \AxiomC{$\Sigma, \psi \vdash \Pi$}
          \RightLabel{\text{ LeftImplies}}
          \BinaryInfC{$\Gamma, \Sigma, \phi\rightarrow \psi \vdash \Delta, \Pi$}
          \DisplayProof &
          \AxiomC{$\Gamma, \phi \vdash \psi, \Delta$}
          \RightLabel{\text{ RightImplies}}
          \UnaryInfC{$\Gamma \vdash \phi \rightarrow \psi,  \Delta$}
          \DisplayProof
          \\[5ex]

          \AxiomC{$\Gamma, \phi \rightarrow \psi \vdash \Delta$}
          \RightLabel{\text { LeftIff}}
          \UnaryInfC{$\Gamma, \phi \leftrightarrow \psi \vdash \Delta$}
          \DisplayProof &
          \AxiomC{$\Gamma \vdash \phi \rightarrow \psi, \Delta$}
          \AxiomC{$\Sigma \vdash \psi \rightarrow \phi, \Pi$}
          \RightLabel{\text{ RightIff}}
          \BinaryInfC{$\Gamma, \Sigma \vdash \phi \leftrightarrow \psi,  \Delta, \Pi$}
          \DisplayProof
          \\[5ex]

          \AxiomC{$\Gamma \vdash \phi, \Delta$}
          \RightLabel{\text { LeftNot}}
          \UnaryInfC{$\Gamma, \neg \phi \vdash \Delta$}
          \DisplayProof &
          \AxiomC{$\Gamma, \phi \vdash \Delta$}
          \RightLabel{\text{ RightNot}}
          \UnaryInfC{$\Gamma \vdash \neg \phi ,  \Delta$}
          \DisplayProof
          \\[5ex]

          \AxiomC{$\Gamma, \phi[x := t] \vdash \Delta$}
          \RightLabel{\text { LeftForall}}
          \UnaryInfC{$\Gamma, \forall x. \phi  \vdash \Delta$}
          \DisplayProof &
          \AxiomC{$\Gamma \vdash \phi, \Delta$}
          \RightLabel{\text { RightForall}}
          \UnaryInfC{$\Gamma \vdash \forall x. \phi,  \Delta$}
          \DisplayProof
          \\[5ex]

          \AxiomC{$\Gamma, \phi \vdash \Delta$}
          \RightLabel{\text { LeftExists}}
          \UnaryInfC{$\Gamma, \exists x. \phi \vdash \Delta$}
          \DisplayProof &
          \AxiomC{$\Gamma \vdash \phi[x := t], \Delta$}
          \RightLabel{\text { RightExists}}
          \UnaryInfC{$\Gamma \vdash \exists x. \phi,  \Delta$}
          \DisplayProof
        \end{tabular}
      \end{center}
    \end{minipage}}
  \caption{Deduction rules allowed by Lisa's kernel (Part 1). These are typical rules for a sequent calculus for FOL. Different occurrences of the same symbols need not represent equal elements, but only elements with the same \FOLalg{} normal form.}
  \label{fig:deduct_rules_1}
\end{figure}

\begin{figure}
  \scalebox{.9}{
    \begin{minipage}{\textwidth}
      \begin{center}
        \begin{tabular}{l r}

          \multicolumn{2}{c}{
            \AxiomC{$\Gamma \vdash \phi[x:=t], \Delta$}
            \RightLabel{\text { RightEpsilon}}
            \UnaryInfC{$\Gamma \vdash \phi[x:=(\epsilon x. φ)], \Delta$}
            \DisplayProof
          }
          \\[5ex]

          \multicolumn{2}{c}{
            \AxiomC{$\Gamma, \exists y \forall x. (x=y) \leftrightarrow \phi \vdash \Delta$}
            \RightLabel{\text { LeftExistsOne}}
            \UnaryInfC{$\Gamma, \exists ! x. \phi \vdash \Delta$}
            \DisplayProof
          }
          \\[5ex]
          
          \multicolumn{2}{c}{
            \AxiomC{$\Gamma \vdash \exists y \forall x. (x=y) \leftrightarrow \phi , \Delta$}
            \RightLabel{\text { RightExistsOne}}
            \UnaryInfC{$\Gamma \vdash \exists ! x. \phi, \Delta$}
            \DisplayProof
          }
          \\[5ex]

          \multicolumn{2}{c}{
            \AxiomC{$\Gamma \vdash \Delta$}
            \RightLabel{\text{ InstSchema}}
            \UnaryInfC{$\Gamma[(x:A) := (e:A)] \vdash \Delta[(x:A) := (e:A)]$}
            \DisplayProof
          }               
          \\[5ex]

          \multicolumn{2}{c}{
            \AxiomC{$\Gamma, \phi[f := s] \vdash \Delta$}
            \RightLabel{\text{ LeftSubstEq}}
            \UnaryInfC{$\Gamma, \forall \vec x. s(\vec x) \equiv t(\vec x), \phi[f := t] \vdash \Delta$}
            \DisplayProof 
          }
          \\[5ex]

          \multicolumn{2}{c}{
            \AxiomC{$\Gamma \vdash \phi[f := s], \Delta$}
            \RightLabel{\text{ RightSubstEq}}
            \UnaryInfC{$\Gamma,  \forall \vec x. s(\vec x) \equiv t(\vec x) \vdash \phi[f := t], \Delta$}
            \DisplayProof
          }
          \\[5ex]

          \AxiomC{$\Gamma, t = t \vdash \Delta$}
          \RightLabel{\text { LeftRefl}}
          \UnaryInfC{$\Gamma \vdash \Delta$}
          \DisplayProof &
          \AxiomC{}
          \RightLabel{\text{ RightRefl}}
          \UnaryInfC{$\vdash t=t$}
          \DisplayProof
          \\[5ex]

          \multicolumn{2}{c}{
            \AxiomC{$\Gamma_1 \vdash \Delta_1$}
            \RightLabel{\text{ Restate} \text{ if $(\bigwedge\Gamma_1 \rightarrow \bigvee \Delta_1) \sim_\FOLm (\bigwedge\Gamma_2 \rightarrow \bigvee \Delta_2)$}}
            \UnaryInfC{$\Gamma_2 \vdash \Delta_2$}
            \DisplayProof
          }               \\[5ex]

          \multicolumn{2}{c}{
            \AxiomC{}
            \RightLabel{\text{ RestateTrue} \text{ if $\text{True} \sim_\FOLm (\bigwedge\Gamma_2 \rightarrow \bigvee \Delta_2)$}}
            \UnaryInfC{$\Gamma_2 \vdash \Delta_2$}
            \DisplayProof
          }               \\[5ex]

          \multicolumn{2}{c}{
            \AxiomC{$\Gamma_1 \vdash \Delta_1$}
            \RightLabel{\text { Weakening} \text{ if $(\bigwedge\Gamma_1 \rightarrow \bigvee \Delta_1) \leq_\FOLm (\bigwedge\Gamma_2 \rightarrow \bigvee \Delta_2)$}}
            \UnaryInfC{$\Gamma_2 \vdash \Delta_2$}
            \DisplayProof
          }               \\[5ex]

          \multicolumn{2}{c}{
            \AxiomC{}
            \RightLabel{\text { Sorry: admit a statement without proof. Usage transitively tracked.}}
            \UnaryInfC{$\Gamma \vdash \Delta$}
            \DisplayProof
          }
        \end{tabular}
      \end{center}
    \end{minipage}
  }
  \caption{Deduction rules allowed by Lisa's kernel (Part 2). Different occurrences of the same symbols need not represent equal elements, but only elements with the same \FOLalg{} normal form.}
  \label{fig:deduct_rules_2}
\end{figure}

\subsection{Proofs}
A sequent calculus proof is a tree whose nodes are proof steps.
The root of the proof shows the concluding statement, and the leaves are either assumptions (for example, set theoretic axioms) or proof steps taking no premise (Hypothesis, RightRefl and RestateTrue). Figure~\ref{fig:exampleProof} shows an example of a proof tree for Pierce's Law in strict Sequent Calculus.
%
\begin{figure}[ht]
  \centering
  \AxiomC{}
  \RightLabel{\text { Hypothesis}}
  \UnaryInfC{$\phi \vdash \phi$}
  \RightLabel{\text { RightWeakening}}
  \UnaryInfC{$\phi \vdash \phi, \psi$}
  \RightLabel{\text { RightImplies}}
  \UnaryInfC{$\vdash \phi, (\phi \to \psi)$}
  \AxiomC{}
  \RightLabel{\text { Hypothesis}}
  \UnaryInfC{$\phi \vdash \phi$}
  \RightLabel{\text { LeftImplies}}
  \BinaryInfC{$(\phi \to \psi) \to \phi \vdash \phi$}
  \RightLabel{\text { RightImplies}}
  \UnaryInfC{$ \vdash ((\phi \to \psi) \to \phi) \to \phi$}
  \DisplayProof

  \caption{A proof of Pierce's law in Sequent Calculus. The bottommost sequent (root) is the conclusion.}
  \label{fig:exampleProof}
\end{figure}

In the Lisa kernel, proof steps are organised linearly, in a list, to form actual proofs. Each proof step refers to its premises using numbers, which indicate the place of the premise in the proof.
a proof step can also be referred to by multiple subsequent proof steps, so that proofs are actually directed acyclic graphs (DAG) rather than trees. For the proof to be the linearization of a rooted DAG, the proof steps must only refer to numbers smaller than their own in the proof. Indeed, using topological sorting, it is always possible to order the nodes of a directed acyclic graph such that for any node, its predecessors appear earlier in the list.
\autoref{fig:exampleProofLinear} shows the proof of Pierce's Law as linearized in Lisa's kernel.
%
\begin{figure}[ht]
  \begin{align*}
    0 & ~\text{\lstinline|Hypothesis|}       & \quad \phi                     & \vdash \phi                                \\
    1 & ~\text{\lstinline|Weakening|}(0)     & \quad  \phi                    & \vdash \phi, \psi                          \\
    2 & ~\text{\lstinline|RightImplies|}(1)  & \quad                          & \vdash \phi, (\phi \to \psi)               \\
    3 & ~\text{\lstinline|LeftImplies|}(2,0) & \quad (\phi \to \psi) \to \phi & \vdash \phi                                \\
    4 & ~\text{\lstinline|RightImplies|}(3)  & \quad                          & \vdash ((\phi \to \psi) \to \phi) \to \phi
  \end{align*}
  \caption{The proof of Pierce's Law as a sequence of steps using classical Sequent Calculus rules.}
  \label{fig:exampleProofLinear}
\end{figure}

\noindent
Note however that thanks to the $\FOLalg$ equivalence checker, Pierce's law can be proven in a single step:

\begin{gather*}
    0  ~\text{\lstinline|RestateTrue|}        \quad \vdash ((\phi \to \psi) \to \phi) \to \phi .
\end{gather*}

Moreover, proofs are conditional: they can carry an explicit set of assumed sequents, named ``\lstinline|imports|'', which give some starting points to the proof. Typically, these imports will contain previously proven theorems, definitions, or axioms (More on that in section~\ref{sec:TheoremsAndTheories}). For a proof step to refer to an imported sequent, one uses negative integers. $-1$ corresponds to the first sequent of the import list of the proof, $-2$ to the second, etc.

Formally, a proof is a pair made of a list of proof steps and a list of sequents:
%
\begin{gather*}
    \text{\lstinline|Proof(steps:List[ProofStep], imports:List[Sequent])|}
\end{gather*}
%
We call the bottom-most sequent of the last proof step of the proof the ``conclusion'' of the proof.

\noindent
\autoref{fig:exampleProofImports} shows a proof using an import.
%
\begin{figure}[ht]
  \begin{align*}
    -1 & ~\text{\lstinline|Imported Axiom|} & \quad                         & \vdash \neg (x \in \emptyset) \\
    0  & ~\text{\lstinline|Restate|}(-1)    & \quad  (x \in \emptyset)      & \vdash                        \\
    1  & ~\text{\lstinline|LeftSubstEq|}(0) & \quad  (x \in y), y=\emptyset & \vdash                        \\
    2  & ~\text{\lstinline|Restate|}(1)     & \quad  (x \in y)              & \vdash \neg(y=\emptyset)
  \end{align*}
  \caption{A proof that if $x\in y$, then $\neg (y=\emptyset)$, using the empty set axiom. $x$ and $y$ are free variables.}
  \label{fig:exampleProofImports}
\end{figure}

\noindent
Finally, \autoref{fig:exampleProofQuantifiers} shows a proof with quantifiers.
%
\begin{figure}[ht]
  \begin{align*}
    0 & ~\text{\lstinline|RestateTrue|}    & \quad  P(x), Q(x)                              & \vdash P(x) \land Q(x)             \\
    1 & ~\text{\lstinline|LeftForall|}(0)  & \quad  P(x), \forall(x, Q(x))                  & \vdash P(x) \land Q(x)             \\
    2 & ~\text{\lstinline|LeftForall|}(1)  & \quad  \forall(x, P(x)), \forall(x, Q(x))      & \vdash P(x) \land Q(x)             \\
    3 & ~\text{\lstinline|RightForall|}(2) & \quad  \forall(x, P(x)),  \forall(x, Q(x))     & \vdash \forall(x, P(x) \land Q(x)) \\
    4 & ~\text{\lstinline|Restate|}(3)     & \quad  \forall(x, P(x)) \land \forall(x, Q(x)) & \vdash \forall(x, P(x) \land Q(x))
  \end{align*}
  \caption{A proof showing that $\forall$ factorizes over conjunction.}
  \label{fig:exampleProofQuantifiers}
\end{figure}

For every proof step, Lisa's kernel actually expects more than only the premises and conclusion of the rule. The proof step also contains some parameters indicating how the deduction rule is precisely applied. This makes proof checking much simpler, and hence more trustworthy. Outside the kernel, Lisa includes tactic which will infer such parameters automatically (see \autoref{chapt:tactics}), so that in practice the user never has to write them.
\autoref{fig:ExampleProofPierceScala} shows how a kernel proof is written in scala.

\begin{figure}[ht]
  \centering
  \begin{lstlisting}[language=scala, showspaces=false]
val PierceLawProof = SCProof(IndexedSeq(
    Hypothesis( φ |- φ,   φ),
    Weakening( φ |- ( φ, ψ ), 0),
    RightImplies(() |- ( φ, φ ==> ψ ), 1,   φ, ψ)
    LeftImplies(( φ ==> ψ ) ==> φ |- φ, 2, 0,   φ ==> ψ, φ),
    RightImplies(() |- (( φ ==> ψ ) ==> φ) ==> φ, 
                                  3, ( φ ==> ψ ) ==> φ, φ)
), Seq.empty /* no imports */ )
    \end{lstlisting}
  \caption{The proof from~\autoref{fig:exampleProof} written for Lisa's kernel. The second argument (empty here) is the sequence of proof imports. The symbols \lstinline|==>| and \lstinline||-| are ligatures for ==> and |- and are syntactic sugar defined outside the kernel.}
  \label{fig:ExampleProofPierceScala}
\end{figure}

\paragraph*{Subproofs}
To organize proofs, Lisa's kernel also defines the Subproof proof step. A Subproof is a single proof step in a large proof with arbitrarily many premises:
\begin{lstlisting}
  SCSubproof(sp: SCProof, premises: Seq[Int])
\end{lstlisting}
The first argument contain a sequent calculus proof, with one conclusion and arbitrarily many \textit{imports}. The second arguments must justify all the imports of the inner proof with previous steps of the outer proof.
A Subproof only has an organizational purpose and allows to more easily write tactics (see \autoref{chapt:tactics}). In particular, the numbering of proof steps in the inner proof is independent of the location of the subproof step in the outer proof.

\paragraph*{Sorry}

\subsection{Proof Checker}
\label{subsec:proofchecker}

In Lisa, a proof object by itself has no guarantee to be correct. It is possible to write a wrong proof. Lisa contains a \textit{proof checking} function, which, given a proof, will verify if it is correct. To be correct, a proof must satisfy the following conditions:
\begin{enumerate}
  \item No proof step must refer to itself or a posterior proof step as a premise.
  \item Every proof step must be correctly constructed, with the bottom sequent correctly following from the premises by the deduction rule and its arguments.
\end{enumerate}


Given some proof $p$, the proof checker will verify these points. For most proof steps, this typically involve verifying that the premises and the conclusion match according to a transformation specific to the deduction rule.

Hence, most of the proof checker's work consists in verifying that some formulas, or subformulas thereof, are identical. This is where the equivalence checker comes into play. By checking equivalence rather than strict syntactic equality, a lot of steps become redundant and can be merged. That way,  any number of consecutive {LeftAnd}, {RightOr}, {LeftNot}, {RightNot}, {LeftImplies}, {RightImplies}, {LeftIff}, {LeftRefl}, {RightRefl}, {LeftExistsOne} and  {RightExistsOne} proof steps can always be replaced by a single{Weakening} rule. This gives some intuition about how useful the equivalence checker is to simplify proof length.

While most proof steps are oblivious to formula transformations allowed by the equivalence checker, they don't allow transformations of the whole sequent: to easily rearrange sequents according to the sequent semantics (\autoref{eq:SequentSemantic}), one should use the Rewrite or Weakening steps.

Depending on wether the proof is correct or incorrect, the proof checking function will output a \textit{judgement}:
\begin{lstlisting}
  SCValidProof(proof: SCProof)
\end{lstlisting}
or
\begin{lstlisting}
  SCInvalidProof(proof: SCProof, path: Seq[Int], message: String)
\end{lstlisting}

\lstinline|SCInvalidProof|{} indicates an erroneous proof. The second argument point to the faulty proofstep (through subproofs, if any), and the third argument is an error message hinting at why the step is incorrectly applied.

Note that there exists a proof step, called Sorry, used to  represent unimplemented proofs. The conclusion of a Sorry step will always be accepted by the proof checker. Any theorem relying on a Sorry step is not guaranteed to be correct. The usage is, however, transitively tracked and the theorem is marked as relying on Sorry.


\section{Theorems and Theories}
\label{sec:TheoremsAndTheories}

In mathematics as a discipline, theorems don't exist in isolation. They depend on some agreed upon set of axioms, definitions, and previously proven theorems. Formally, theorems are developed within theories. A theory is defined by a language, which contains the symbols allowed in the theory, and by a set of axioms, which are assumed to hold true within it.

In Lisa, a \lstinline|Theory|{} is a mutable object that starts as the pure theory of predicate logic: It has no known symbols and no axioms. Then we can introduce into it elements of Set Theory (symbols $\in$, $\emptyset$, $\bigcup$ and set theory axioms, see Chapter~\ref{chapt:settheory}) or of any other theory.

To conduct a proof inside a \lstinline|Theory|{}, using its axioms, the proof should be normally constructed and the needed axioms specified in the imports of the proof. Then, the proof can be given to the \lstinline|Theory|{} to check, along with \textit{justifications} for all imports of the proof. A justification is either an axiom, a previously proven theorem, or a definition. The \lstinline|Theory|{} object will check that every import of the proof is properly justified by a \textit{justification} in the theory, i.e. that the proof is in fact not conditional in the theory. Then, it will pass the proof to the proof checker. If the proof is correct, it will return a \lstinline|Theorem|{} encapsulating the sequent. This theorem will be allowed to be used in all further proofs as an import, exactly like an axiom. Axioms and theorems also have a name.

\subsection{Definitions}
\label{subsec:definitions}
The user can also introduce definitions in the \lstinline|Theory|{}.
Lisa's kernel allows to define two kinds of objects: Function (or Term) symbols and Predicate symbols.


\begin{figure}
  A definition in Lisa is one of those two kinds of objects: A predicate definition or a function definition.
  \begin{lstlisting}
  PredicateDefinition(
    label: ConstantAtomicLabel,
    expression: LambdaTermFormula
  )
\end{lstlisting}
  So that
  \begin{lstlisting}
    PredicateDefinition(P, lambda(Seq(x1,...,x2), φ)) 
  \end{lstlisting}
  corresponds to \\
  \hspace*{1.3em}``For any $\vec{x}$, let $P^n(\vec{x}) := \phi_{\vec{x}}$"

  \vspace*{2em}
  \begin{lstlisting}
  FunctionDefinition(
    label: ConstantFunctionLabel,
    out: VariableLabel, 
    expression: LambdaTermFormula
  )
\end{lstlisting}
  So that
  \begin{lstlisting}
    FunctionDefinition(f, y, lambda(Seq(x1,...,x2), φ)) 
  \end{lstlisting}
  corresponds to \\
  \hspace*{1.3em}``For any $\vec{x}$, let $f^n(\vec{x}) \textnormal{ be the unique } y \textnormal{ such that } \varphi$ holds."

  \caption{Definitions in Lisa.}
  \label{fig:definitions}
\end{figure}

\autoref{fig:definitions} shows how to define and use new function and predicate symbols. To define a predicate on $n$ variables, we must provide a formula along with $n$ distinguished free variables. Then, this predicate can be freely used and at any time substituted by its definition. Functions are slightly more complicated: to define a function $f$, one must first prove a statement of the form
$$\exists ! y. \phi_{y, x_1,...,x_k}$$
Then we obtain the defining property
$$\forall y. (f(x_1,...,x_k)=y) \leftrightarrow \phi_{y, x_1,...,x_k}$$
from which we can deduce in particular $\phi[f(x_1,...,x_k)/y]$.
The special case where $n=0$ defines constant symbols. The special case where $\phi$ is of the form $y=t$, with possibly the $x$'s free in $t$ lets us recover a more simple definition \textit{by alias}, i.e. where  $f$ is simply a shortcut for a more complex term $t$.
This definitional mechanism requiring a proof of unique existence is typically called \textit{extension by definition}, and allows us to extend the theory without changing what is or isn't provable, see \autoref{sec:definitions}.

The \lstinline|Theory|{} object is responsible of keeping track of all symbols which have been defined so that it can detect and refuse conflicting definitions. As a general rule, definitions should have a unique identifier and can't contain free schematic symbols.

Once a definition has been introduced, future theorems can refer to those definitional axioms by importing the corresponding sequents in their proof and providing justification for those imports when the proof is verified, just like with axioms and theorems.

\autoref{fig:justifications} shows the types of justification in a theory (Theorem, Axiom, Definition). \autoref{fig:theorysetters} shows how to introduce new justifications in the theory.



  {
    \def\arraystretch{4}

    \begin{figure}[hp]
      % Justifications:
      \begin{center}
        \begin{tabular}{l|l}
          Explanation            & Data Type
          \\ \hline

          A proven theorem       &
          \begin{lstlisting}[linewidth=19.5em]
  Theorem(
    name: String,
    proposition: Sequent
  )

          \end{lstlisting}
          \\ %\hline

          An axiom of the theory &
          \begin{lstlisting}[linewidth=19.5em]
  Axiom(
    name: String,
    ax: Formula
  )

          \end{lstlisting}
          \\ %\hline

          A predicate definition &
          \begin{lstlisting}[linewidth=19.5em]
  PredicateDefinition(
    label: ConstantAtomicLabel,
    expression: LambdaTermFormula
  )

          \end{lstlisting}
          \\ %\hline

          A function definition  &
          \begin{lstlisting}[linewidth=19.5em]
  FunctionDefinition(
    label: ConstantFunctionLabel,
    out: VariableLabel,
    expression: LambdaTermFormula
  )

          \end{lstlisting}
          \\ %\hline
        \end{tabular}

        \caption{The different types of justification in a \lstinline|Theory|{} object.}
        \label{fig:justifications}
      \end{center}
    \end{figure}

    \begin{figure}[hp]
      % Setters/Constructors:
      \begin{center}
        \begin{tabular}{l|l}
          Explanation & Function
          \\ \hline

          \makecell[l]{Add a new theorem \\to the theory} &
          \begin{lstlisting}[linewidth=19.5em]
  makeTheorem(
    name: String,
    statement: Sequent,
    proof: SCProof,
    justs: Seq[Justification]
  )
          \end{lstlisting}
          \\ %\hline

          \makecell[l]{Add a new axiom   \\ to the theory} &
          \begin{lstlisting}[linewidth=19.5em]
  addAxiom(
    name: String,
    f: Formula
  )
          \end{lstlisting}
          \\ %\hline

          \makecell[l]{Make a new        \\predicate definition} &
          \begin{lstlisting}[linewidth=19.5em]
  makePredicateDefinition(
    label: ConstantAtomicLabel,
    expression: LambdaTermFormula
  )
          \end{lstlisting}
          \\ %\hline

          \makecell[l]{Make a new        \\function definition} &
          \begin{lstlisting}[linewidth=19.5em]
  makeFunctionDefinition(
    proof: SCProof,
    justifications: Seq[Justification],
    label: ConstantFunctionLabel,
    out: VariableLabel,
    expression: LambdaTermFormula
  )
          \end{lstlisting}
          \\ %\hline
        \end{tabular}
        \caption{The interface of a \lstinline|Theory|{} object to introduce new theorems, axioms and definitions.}

        \label{fig:theorysetters}
      \end{center}
    \end{figure}







    \iffalse
      \begin{figure}[hp]
        % Getters:
        \begin{center}
          \begin{tabular}{l|l}
            Explanation & Function
            \\ \hline

            \makecell[l]{Check if all symbols in a        \\formula, term or sequent\\belong to the theory.} &
            \begin{lstlisting}
belongsToTheory(phi: Formula)
belongsToTheory(t: Term)
belongsToTheory(s: Sequent)
\end{lstlisting}
            \\ %\hline

            \makecell[l]{Return the list of symbols       \\and definitions in the theory} &
            \begin{lstlisting}
language()
\end{lstlisting}
            \\ %\hline

            \makecell[l]{Check if a label is              \\a symbol of the theory} &
            \begin{lstlisting}
isSymbol(label: ConstantLabel)
\end{lstlisting}
            \\ %\hline

            \makecell[l]{Check if a label is \textit{not} \\already a symbol of the theory} &
            \begin{lstlisting}
isAvailable(label: ConstantLabel)
\end{lstlisting}
            \\ %\hline

            \makecell[l]{Return the list of               \\axioms in the theory} &
            \begin{lstlisting}
axiomsList()
\end{lstlisting}
            \\ %\hline

            \makecell[l]{Check if a formula is            \\an axiom of the theory} &
            \begin{lstlisting}
isAxiom(f: Formula)
\end{lstlisting}
            \\ %\hline

            \makecell[l]{Return the Axiom matching        \\ the given name or formula,\\ if it exists} &
            \begin{lstlisting}
getAxiom(f: Formula)
getAxiom(name: String)
\end{lstlisting}
            \\ %\hline
            \makecell[l]{Return the Definition            \\of a given Label, if defined} &
            \begin{lstlisting}
getDefinition(label: ConstantLabel)
\end{lstlisting}
            \\ %\hline

            \makecell[l]{Return the Theorem object with   \\the given name, if it is one.} &
            \begin{lstlisting}
getTheorem(name: String)
\end{lstlisting}
            \\ %\hline
          \end{tabular}
          \caption{The static interface of a \lstinline|Theory|{} object.}
          \label{fig:theorygetters}
        \end{center}
      \end{figure}

    \fi
  }

\section{Using Lisa's Kernel}
\label{sec:kernelHelpers}
The kernel itself is a logical core, whose main purpose is to attest correctness of mathematical developments and proofs. In particular, it is not intended to be used directly to formalise a large library, as doing so would be very verbose. It instead serves as either a foundation for Lisa's user interface and automation, or as a tool to write and verify formal proofs produced by other programs.
Nonetheless, Lisa's kernel comes with a set of utilities and features and syntactic sugar that make the kernel more user-friendly.
\subsection{Syntactic Sugar}

\paragraph{Aliases}
Scala accepts most unicode symbols in identifiers, allowing Lisa to define alternative representation for logical symbols
\begin{center}
  \begin{tabular}{| c | c |}

    \hline
    Original symbol       & Alias                      \\
    \hline

    \lstinline|top|       & \lstinline|True, ⊤ |       \\ \hline
    \lstinline|bot|       & \lstinline|False, ⊥ |      \\ \hline
    \lstinline|And|       & \lstinline|and, /\ |       \\ \hline
    \lstinline|Or|        & \lstinline|or, \/ |        \\ \hline
    \lstinline|Implies|   & \lstinline|implies, ==> |  \\ \hline
    \lstinline|Iff|       & \lstinline|iff, <=> |      \\ \hline
    \lstinline|Forall|    & \lstinline|forall, ∀ |     \\ \hline
    \lstinline|Exists|    & \lstinline|exists, ∃ |     \\ \hline
    \lstinline|ExistsOne| & \lstinline|existsOne, ∃! | \\ \hline
  \end{tabular}
\end{center}
\paragraph{Identifiers}
An identifier is a pair of a string and a number. Note that Lisa kernel does not accept whitespace nor symbols among \lstinline|()[]{}_| as part of identifiers. The underscore can be used to write both the string and the integer part of an identifier at once. For example,

\begin{lstlisting}[language=Scala]
  val x: VariableLabel("x_4")
\end{lstlisting}

is automatically transformed to

\begin{lstlisting}[language=Scala]
  val x: VariableLabel(Identifier("x", 4))
\end{lstlisting}

\paragraph{Application}
With the following symbols:
\begin{lstlisting}[language=Scala]
  val x: VariableLabel("x")
  val y: VariableLabel("x")
  val f: SchematicFunctionLabel("f", 2)
\end{lstlisting}
the strict syntax to construct the term \lstinline[language=Scala]|f(x, y)| is
\begin{lstlisting}[language=Scala]
  Term(f, Seq(Term(x, Nil), Term(y, Nil)))
\end{lstlisting}
Extensions and implicit conversions allow one to simply write
\begin{lstlisting}[language=Scala]
  f(x, y)
\end{lstlisting}
for the same result. The same holds with predicates and connectors. Moreover, binary symbols can be written infix, allowing the following syntax:

\begin{lstlisting}[language=Scala]
  (f(x, y) === f(y, x)) ==> (x === y)
\end{lstlisting}

\paragraph{Sequents}
The strict syntax to construct the sequent $\phi, \psi \vdash \gamma, \delta$ is
\begin{lstlisting}[language=Scala]
  Sequent(Set(phi, psi), Set(phi, psi))
\end{lstlisting}
but thanks again to  extensions and implicit conversions, Lisa accepts
\begin{lstlisting}[language=Scala]
  (phi, psi) |- (phi, psi)
\end{lstlisting}
Where \lstinline@|-@ is the ligature for { |- } or \lstinline@|@ + \lstinline@-@. More generally, the left and right sides of \lstinline@|-@ can be any of:
\vspace*{-0.7em}
\begin{itemize}
  \setlength\itemsep{-0.5em}
  \item \lstinline|()| --- \lstinline|Unit|, translated to an empty set
  \item a \lstinline|Formula|
  \item a \lstinline|Tuple[Formula]|
  \item an \lstinline|Iterable[Formula]| (\lstinline|Set|, \lstinline|List|...)
\end{itemize}
\paragraph{Lambdas}
A Lambda expression can be created with the lambda keyword, writing a single variable by itself, or providing a sequence if the function takes multiple arguments. For example,
\begin{lstlisting}[language=Scala]
  lambda(x, x+x): LambdaTermTerm
  lambda(Seq(x, y, z), x+y+z): LambdaTermTerm
  lambda(x, x === x): LambdaTermFormula
  lambda(Seq(x, y), (x+x) === y)): LambdaTermFormula
  lambda(X, X /\ y === y): LambdaFormulaFormula
  lambda(Seq(X, Y), X <=> Y): LambdaFormulaFormula
\end{lstlisting}
Moreover, a term \lstinline|t| is automatically converted to a LambdaTermTerm \lstinline|lambda(Seq(), t)| with an empty list of arguments when needed, and similarly for LambdaTermFormula and LambdaFormulaFormula.

\vspace{2em}
\subsection{How to write helpers}
These helpers and syntactic sugar are made possible by Scala's extensions and implicit conversions. Extension allow to add methods to an object a posteriori of its definition. This is especially convenient for use, as it allows us to define such helpers outside of the kernel, keeping it small.
For example, to write \lstinline|f(x, y)|, the object \lstinline|f: SchematicFunctionLabel| must have a method called \lstinline|apply|. It is defined as
\begin{lstlisting}[language=Scala]
  extension (label: TermLabel) {
    def apply(args: Term*): Term = Term(label, args)
  }
\end{lstlisting}
where \lstinline|Term*| indicates that the function can take arbitrary many Terms as arguments.
We can also defines infix symbols this way. An expression \lstinline|a === b| is in fact syntactic sugar for \lstinline|a.===(b)|. So we define:
\begin{lstlisting}[language=Scala]
  extension (t: Term) {
    infix def ===(u: Term): Term = Term(equality, Seq(t, u))
  }
\end{lstlisting}
And similarly for other symbols such as \lstinline|/\|, \lstinline|\/|, \lstinline|==>|, \lstinline|<=> |.

Now, consider again
\begin{lstlisting}[language=Scala]
  val x: TermLabel = VariableLabel("x")
  val y: TermLabel = VariableLabel("x")
  val f: SchematicFunctionLabel("f", 2)
\end{lstlisting}
even with the above \lstinline|apply| trick, \lstinline|f(x, y)| would not compile, since \lstinline|f| can apply to \lstinline|Term| arguments, but not to \lstinline|TermLabel|. Hence we first need to apply \lstinline|x| and \lstinline|y| to an empty list of argument, such as in \lstinline|f(x(), y())|.
This can be done automatically with implicit conversions. Implicit conversion is the mechanism allowing to cast an object of a type to an other in a canonical way. It is defined with the \lstinline|given| keyword:
%
\begin{lstlisting}[language=Scala]
  given Conversion[TermLabel, Term] = (t: Term) => Term(t, Seq())
\end{lstlisting}
%
Now, every time a \lstinline|TermLabel| is written in a place where a \lstinline|Term| is expected, it will be converted implicitly.

To learn more about Scala 3 and its capabilities, see its documentation at {\footnotesize\url{https://docs.scala-lang.org/scala3/book/introduction.html}}. 

